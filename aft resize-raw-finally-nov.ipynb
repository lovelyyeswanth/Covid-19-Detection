{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Detection using SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## used Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-05T13:58:53.862926Z",
     "iopub.status.busy": "2023-09-05T13:58:53.862471Z",
     "iopub.status.idle": "2023-09-05T13:58:56.165543Z",
     "shell.execute_reply": "2023-09-05T13:58:56.162320Z",
     "shell.execute_reply.started": "2023-09-05T13:58:53.862891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "print(\"Setup Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load and split train set and test set\n",
    "#### to Generalize\n",
    "- resize to (256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-05T13:58:56.168805Z",
     "iopub.status.busy": "2023-09-05T13:58:56.168267Z",
     "iopub.status.idle": "2023-09-05T13:59:06.607790Z",
     "shell.execute_reply": "2023-09-05T13:59:06.606547Z",
     "shell.execute_reply.started": "2023-09-05T13:58:56.168759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_data(path):\n",
    "    data = []\n",
    "    for (dirpath, _, filenames) in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            image_path = os.path.join(dirpath, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            if image is not None:\n",
    "                if len(image.shape) == 3:  # Check if it's an RGB image\n",
    "                    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                else:\n",
    "                    gray_image = image  # Image is already in grayscale\n",
    "\n",
    "                resized_gray_image = cv2.resize(gray_image, (256, 256)).flatten()\n",
    "                data.append(resized_gray_image)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "path = 'resized_dataset'\n",
    "print(\"1\")\n",
    "normal_train    = load_data(path + '/train/NORMAL/')\n",
    "print(\"2\")\n",
    "pneumonia_train = load_data(path + '/train/PNEUMONIA/')\n",
    "print(\"3\")\n",
    "normal_test     = load_data(path + '/test/NORMAL/')\n",
    "print(\"4\")\n",
    "pneumonia_test  = load_data(path + '/test/PNEUMONIA/')\n",
    "print(\"5\")\n",
    "\n",
    "# Merge both cases into an array\n",
    "X_train = normal_train + pneumonia_train\n",
    "X_test  = normal_test  + pneumonia_test\n",
    "\n",
    "#in these set gonna be thresholded\n",
    "X_train2 = X_train\n",
    "X_test2 = X_test\n",
    "\n",
    "# Generate outcomes for them\n",
    "y_train = [0] * len(normal_train) + [1] * len(pneumonia_train)\n",
    "y_test  = [0] * len(normal_test)  + [1] * len(pneumonia_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5914"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "644"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셔플\n",
    "permutation = np.random.permutation(len(X_train))\n",
    "X_train = np.array(X_train)[permutation]\n",
    "X_train2 = np.array(X_train)[permutation]\n",
    "y_train = np.array(y_train)[permutation]\n",
    "\n",
    "permutation = np.random.permutation(len(X_test))\n",
    "X_test = np.array(X_test)[permutation]\n",
    "X_test2 = np.array(X_test)[permutation]\n",
    "y_test = np.array(y_test)[permutation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define and train other classifiers\n",
    "Rocchio_classifier = NearestCentroid()\n",
    "Decision_Tree_Classifier = make_pipeline(DecisionTreeClassifier())\n",
    "ada_classifier = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "classifiers = [\n",
    "    (\"Rocchio classifier\", Rocchio_classifier),\n",
    "    (\"Decision Tree Classifier\", Decision_Tree_Classifier),\n",
    "    (\"AdaBoost Classifier\", ada_classifier)\n",
    "]\n",
    "\n",
    "for clf_name, clf in classifiers:\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train2, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = clf.predict(X_test2)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Plotting the confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "                xticklabels=['Class 0', 'Class 1'],\n",
    "                yticklabels=['Class 0', 'Class 1'])\n",
    "    plt.title(f\"Confusion Matrix - {clf_name}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "\n",
    "    # Other metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"{clf_name} Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
